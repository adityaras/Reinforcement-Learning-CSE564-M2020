{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3lCS1syeRA8M2x0M+CcFC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KNV9MmA3JJn"
      },
      "source": [
        "# The Following Libraries have been imported\n",
        "#   1. Numpy: Used throughout the file, for random numbers, solving equations, \n",
        "#      and initializing 2-D Matrices\n",
        "#   2. Copy: To deepcopy values (In Iterative Algorithms)\n",
        "\n",
        "import numpy as np\n",
        "import copy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NndYoXTO2zpg"
      },
      "source": [
        "##Question 2: Gridworld Problem - Solving a System of Linear Equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xsXTNbDfLO1"
      },
      "source": [
        "The function **next_step** takes in two arguments\n",
        "  1.   state: The state argument is of the form (i,j) where i and j represents the row and column respectively.\n",
        "  2.   action: The action argument is also a tuple which can be one of the four allowed actions in the problem i.e. (North, South, East and West).\n",
        "\n",
        "According to the conditions i.e. taking care of out of bound conditions, and the special states given A and B, the next state S' and also the corresponding reward is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-fwezicA1Uz"
      },
      "source": [
        "def next_step(state, action):\n",
        "  if state == (0,1):\n",
        "    return (4,1), 10\n",
        "  elif state == (0,3):\n",
        "    return (2,3), 5\n",
        "  else:\n",
        "    if ((state[0]+action[0])>=0 and (state[0]+action[0])<=4 and (state[1]+action[1])>=0 and (state[1]+action[1])<=4):\n",
        "      return (state[0]+action[0],state[1]+action[1]), 0\n",
        "    else:\n",
        "      return state, -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls797DsJtTW2"
      },
      "source": [
        "The function **gridworld_prob_v_pi_s** sets up the coefficient matrix and constant matrix for the system of equations $v_{\\pi}(s)$ and $v_{\\pi}(s')$. The system of equations in represented by:\n",
        "  \n",
        "*   $v_{\\pi}(s) = \\Sigma_{a} \\pi(a|s) [\\Sigma_{s',r} p(s',r|s,a)[ r + \\gamma v_{\\pi}(s')]]$\n",
        "\n",
        "The Coefficient Matrix is initialised as (states $ \\times $ states) identity matrix. The Constant Matrix is initialised as a Zero Matrix of size (states $ \\times $ 1) .\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUCy4j2R3Enq"
      },
      "source": [
        "def gridworld_prob_v_pi_s(gamma, grid_rows, grid_cols, actions, pi):\n",
        "  states = int(grid_rows * grid_cols)\n",
        "  coeff_matrix = np.identity(states)\n",
        "  const_matrix = np.zeros((states,1))\n",
        "  curr_state = -1\n",
        "  for i in range(grid_rows):\n",
        "    for j in range(grid_cols):\n",
        "      curr_state += 1\n",
        "      for a in actions:\n",
        "        s_dash, r = next_step((i,j),a)\n",
        "        coeff_matrix[curr_state][s_dash[1]+(grid_rows*s_dash[0])] -= pi*gamma\n",
        "        const_matrix[curr_state] += pi*r\n",
        "  v_pi_s = np.linalg.solve(coeff_matrix, const_matrix)\n",
        "  v_pi_s = v_pi_s.reshape((grid_rows,grid_cols))\n",
        "\n",
        "  return v_pi_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaW2dyvgEB_7"
      },
      "source": [
        "gamma = 0.9\n",
        "grid_rows = 5\n",
        "grid_cols = 5\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "pi = 0.25\n",
        "v_pi_s = gridworld_prob_v_pi_s(gamma, grid_rows, grid_cols, actions, pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4scxifBEmAV",
        "outputId": "80e7bb41-d793-416d-e9d6-1d352f2140fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print((v_pi_s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3.30899634  8.78929186  4.42761918  5.32236759  1.49217876]\n",
            " [ 1.52158807  2.99231786  2.25013995  1.9075717   0.54740271]\n",
            " [ 0.05082249  0.73817059  0.67311326  0.35818621 -0.40314114]\n",
            " [-0.9735923  -0.43549543 -0.35488227 -0.58560509 -1.18307508]\n",
            " [-1.85770055 -1.34523126 -1.22926726 -1.42291815 -1.97517905]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sFPXSv-RWyl"
      },
      "source": [
        "## Question 4: Optimal State Value and Policy Functions - Solving a System of Non-Linear Equations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGQ8mWLeBrG-"
      },
      "source": [
        "The System of Non Linear Equations in the example is approximated using Value Iteration. A threshold value, Theta ( $\\theta$ ) set to 1e-4 which acts as a stopping criterion for the iteration process.\n",
        "\n",
        "The Optiml Policy Function takes into account that there might be more than one optimal action and the final optimal Policy is created with keeping this is mind. For every action the action-value function $q(s,a)$ is calculated. From these $q(s,a)$ values $a_{*}$ is calculated for each state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6MqNSzSRV0R"
      },
      "source": [
        "def grid_world_problem_optimal(gamma, grid_rows, grid_cols, actions, theta):\n",
        "  v_s_i = np.zeros((grid_cols,grid_rows))\n",
        "  v_s_i1 = np.zeros((grid_cols,grid_rows))\n",
        "  curr_state = -1\n",
        "  while True:\n",
        "    for i in range(grid_rows):\n",
        "      for j in range(grid_cols):\n",
        "        max_v_s = []\n",
        "        for a in actions:\n",
        "          s_dash, r = next_step((i,j),a)\n",
        "          v_s = r + gamma*v_s_i[s_dash[0]][s_dash[1]]\n",
        "          max_v_s.append(v_s)\n",
        "        v_s_i1[i][j] = max(max_v_s) \n",
        "    delta = abs(v_s_i1 - v_s_i).max()\n",
        "    # print(delta)\n",
        "    if delta<theta:\n",
        "      return v_s_i1\n",
        "    else:\n",
        "      v_s_i = copy.deepcopy(v_s_i1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xThOhYvAe9Qn"
      },
      "source": [
        "gamma = 0.9\n",
        "grid_rows = 5\n",
        "grid_cols = 5\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "theta = 0.00001\n",
        "v_star = grid_world_problem_optimal(gamma, grid_rows, grid_cols, actions, theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R2B5PArfQmI",
        "outputId": "6ad70cb0-9576-49c7-e1ee-cc5f4ec8ac51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(v_star)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[21.97747068 24.41941186 21.97747068 19.41941186 17.47747068]\n",
            " [19.77972361 21.97747068 19.77972361 17.80174304 16.02156873]\n",
            " [17.80174304 19.77972361 17.80174304 16.02156873 14.41941186]\n",
            " [16.02156873 17.80174304 16.02156873 14.41941186 12.97747068]\n",
            " [14.41941186 16.02156873 14.41941186 12.97747068 11.67972361]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw-q-2xdvkoa"
      },
      "source": [
        "def grid_world_problem_optimal_policy(actions, grid_rows, grid_cols,v_star,dir):\n",
        "  state = -1\n",
        "  for i in range(grid_rows):\n",
        "      for j in range(grid_cols):\n",
        "        state += 1\n",
        "        q_s_a = np.zeros(len(actions))\n",
        "        k = 0\n",
        "        for a in actions:\n",
        "            s_dash, r = next_step((i,j), a)\n",
        "            q_s_a[k] = r + (gamma * v_star[s_dash[0]][s_dash[1]])\n",
        "            k += 1\n",
        "        a_star = max(q_s_a)\n",
        "        s = \"\"\n",
        "        for q in range(len(q_s_a)):\n",
        "          if a_star == q_s_a[q]:\n",
        "            s += dir[q] + \"+\"\n",
        "        s = s[:-1]\n",
        "        print(s, end=\"\")\n",
        "        if (state+1)%5 == 0:\n",
        "          print('\\n')\n",
        "        else:\n",
        "          print(\"; \", end =\"\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9BFTmrozQ_l",
        "outputId": "70fcc9f6-485e-4a24-8ffe-e2c7c18c33cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "gamma = 0.9\n",
        "grid_rows = 5\n",
        "grid_cols = 5\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "dir = {0:\"South\", 1:\"East\", 2:\"North\", 3:\"West\"}\n",
        "grid_world_problem_optimal_policy(actions, grid_rows, grid_cols,v_star,dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "East; South+East+North+West; West; South+East+North+West; West\n",
            "\n",
            "East+North; North; North+West; West; West\n",
            "\n",
            "East+North; North; North+West; North+West; North+West\n",
            "\n",
            "East+North; North; North+West; North+West; North+West\n",
            "\n",
            "East+North; North; North+West; North+West; North+West\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEDPWXRo-73a"
      },
      "source": [
        "## Question 6: Policy and Value Iteration in the Gridworld Example 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6OsD3wVBojJ"
      },
      "source": [
        "### Policy Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBNr_I6cISb2"
      },
      "source": [
        "Firstly a new **next_step_ex41** is implemented according to the new Grid World Conditions, which is very similar to the one implemented above but also takes an additional argument, *grid_rows* to take care of terminal states.\n",
        "\n",
        "For Policy Iteration,\n",
        "Two functions are implemented: Followed Instructions provided in the Textbook (Sutton)\n",
        "\n",
        "\n",
        "1.   Policy Evaluation\n",
        "2.   Policy Improvement\n",
        "\n",
        "The Bug mentioned in Exercise 4.4 will not take place because we take all possible maximum values and update them simultaneously. As a result the bug that the policy may oscillate between two maximum values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDT5IcaU-6P6"
      },
      "source": [
        "def next_step_ex41(state, action, grid_rows):\n",
        "  if ((state[0]+action[0])>=0 and (state[0]+action[0])<4 and (state[1]+action[1])>=0 and (state[1]+action[1])<4):\n",
        "    if (state[0]+action[0], state[1]+action[1]) == (0,0) or (state[0]+action[0], state[1]+action[1]) == (grid_rows-1, grid_rows-1):\n",
        "      return (grid_rows-1,grid_cols-1), -1\n",
        "    else:\n",
        "      return (state[0]+action[0],state[1]+action[1]), -1\n",
        "  else:\n",
        "    return state, -1"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLNcnfzvifcl"
      },
      "source": [
        "def grid_world_4x4_policy_eval(v_pi, grid_rows, grid_cols, actions, pi_mat,term_state, theta):\n",
        "  # v_pi = np.zeros((grid_rows,grid_cols))\n",
        "  while(True):\n",
        "    delta = 0\n",
        "    for i in range(grid_rows):\n",
        "      for j in range(grid_cols):\n",
        "        if (i,j) not in term_state:\n",
        "          v = copy.deepcopy(v_pi[i][j])\n",
        "          val = 0\n",
        "          c = 0\n",
        "          for a in actions:\n",
        "            s_dash, r = next_step_ex41((i,j), a, grid_rows)\n",
        "            val += pi_mat[i][j][c] * (r + v_pi[s_dash[0]][s_dash[1]])\n",
        "            c += 1\n",
        "          v_pi[i][j] = val\n",
        "          delta = max(delta, abs(v_pi[i][j] - v))\n",
        "          # print(\"Delta \"+str(delta))\n",
        "    if delta < theta:\n",
        "      return v_pi\n",
        "    "
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izH4-NdXbPi3"
      },
      "source": [
        "grid_rows = 4\n",
        "grid_cols = 4\n",
        "v_pi = np.zeros((grid_rows,grid_cols))\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "pi = 0.25\n",
        "theta = 0.00001\n",
        "term_state = [(0,0),(grid_rows-1,grid_cols-1)]\n",
        "dir = {0:\"South\", 1:\"East\", 2:\"North\", 3:\"West\"}\n",
        "v_pi = grid_world_4x4_policy_eval(v_pi,grid_rows, grid_cols, actions, pi,term_state, theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d8EvaVxcTPo",
        "outputId": "4930edb4-8e64-48a9-8ff0-1c70d7f02aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(v_pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.         -13.99993529 -19.99990698 -21.99989761]\n",
            " [-13.99993529 -17.9999206  -19.99991379 -19.99991477]\n",
            " [-19.99990698 -19.99991379 -17.99992725 -13.99994569]\n",
            " [-21.99989761 -19.99991477 -13.99994569   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wenO9777dQaG"
      },
      "source": [
        "def grid_world_4x4_policy_improv(pi_mat,v_pi,grid_rows, grid_cols, actions, pi,term_state, action_map):\n",
        "  no_actions = len(actions)\n",
        "  # pi_mat = np.full((grid_rows,grid_cols,no_actions),pi)\n",
        "  policy_stable = True\n",
        "  for i in range(grid_rows):\n",
        "    for j in range(grid_cols):\n",
        "      if (i,j) not in term_state:\n",
        "        old_a = copy.deepcopy(pi_mat[i][j])\n",
        "        a_ind = 0\n",
        "        returns = []\n",
        "        for a in actions:\n",
        "          s_dash, r = next_step_ex41((i,j), a, grid_rows)\n",
        "          returns.append(r + v_pi[s_dash[0]][s_dash[1]])\n",
        "        max_val = max(returns)\n",
        "        max_a = []\n",
        "        for  ret in range(len(returns)):\n",
        "          if returns[ret] == max_val:\n",
        "            max_a.append(ret)\n",
        "        pi_mat[i][j] = [0.] * no_actions\n",
        "        for a_ind in max_a:\n",
        "          pi_mat[i][j][a_ind] = (1/len(max_a))\n",
        "        for ind in range(len(old_a)):\n",
        "          if (old_a[ind] != pi_mat[i][j][ind]):\n",
        "            policy_stable = False\n",
        "            break\n",
        "  return pi_mat, policy_stable          "
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKUvuBagjsS_",
        "outputId": "e5239cdf-7461-4e5a-b57a-08e3a7d9e023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "grid_rows = 4\n",
        "grid_cols = 4\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "action_map = {0:(1,0),1:(0,1),2:(-1,0),3:(0,-1)}\n",
        "pi = 0.25\n",
        "term_state = [(0,0),(grid_rows-1,grid_cols-1)]\n",
        "dir = {0:\"D\", 1:\"R\", 2:\"U\", 3:\"L\"}\n",
        "no_actions = len(actions)\n",
        "pi_mat = np.full((grid_rows,grid_cols,no_actions),pi)\n",
        "print(grid_world_4x4_policy_improv(pi_mat,v_pi,grid_rows, grid_cols, actions, pi,term_state, action_map))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[[0.25, 0.25, 0.25, 0.25],\n",
            "        [0.  , 0.  , 0.  , 1.  ],\n",
            "        [0.  , 0.  , 0.  , 1.  ],\n",
            "        [0.  , 0.  , 0.  , 1.  ]],\n",
            "\n",
            "       [[0.  , 0.  , 1.  , 0.  ],\n",
            "        [0.  , 0.  , 0.5 , 0.5 ],\n",
            "        [0.  , 0.  , 0.  , 1.  ],\n",
            "        [1.  , 0.  , 0.  , 0.  ]],\n",
            "\n",
            "       [[0.  , 0.  , 1.  , 0.  ],\n",
            "        [0.  , 0.  , 1.  , 0.  ],\n",
            "        [0.  , 1.  , 0.  , 0.  ],\n",
            "        [1.  , 0.  , 0.  , 0.  ]],\n",
            "\n",
            "       [[0.  , 0.  , 1.  , 0.  ],\n",
            "        [0.  , 1.  , 0.  , 0.  ],\n",
            "        [0.  , 1.  , 0.  , 0.  ],\n",
            "        [0.25, 0.25, 0.25, 0.25]]]), False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q-oTKKTB-Oz"
      },
      "source": [
        "def fin_policy(pi_mat,dir,grid_rows,grid_cols,term_state):\n",
        "  for i in range(grid_rows):\n",
        "    for j in range(grid_cols):\n",
        "      if (i,j) not in term_state:\n",
        "        val = max(pi_mat[i][j])\n",
        "        s=\"\"\n",
        "        for k in range(len(pi_mat[i][j])):\n",
        "          if val == pi_mat[i][j][k]:\n",
        "            s+=dir[k]\n",
        "        print(s,end=\"\")\n",
        "      else:\n",
        "        print(\"#\",end=\"\")\n",
        "      if (j==grid_cols-1):\n",
        "        print(\"\\n\")\n",
        "      else:\n",
        "        print(\";\",end=\" \")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0XbH3bvAqH"
      },
      "source": [
        "def grid_4x4_PI(grid_rows, grid_cols, actions, pi,term_state, theta, action_map,dir):\n",
        "  i = 0\n",
        "  v_pi = np.zeros((grid_rows,grid_cols))\n",
        "  no_actions = len(actions)\n",
        "  pi_mat = np.full((grid_rows,grid_cols,no_actions),pi)\n",
        "  while True:\n",
        "    print(\"Iteration \"+str(i))\n",
        "    print(\"Evaluating Policy...\")\n",
        "\n",
        "    v = grid_world_4x4_policy_eval(v_pi, grid_rows, grid_cols, actions, pi_mat,term_state, theta)\n",
        "    v_pi = copy.deepcopy(v)\n",
        "    print(v_pi)\n",
        "\n",
        "    print(\"Improving Policy...\")\n",
        "\n",
        "    pi_mat_temp, stable = grid_world_4x4_policy_improv(pi_mat,v_pi,grid_rows, grid_cols, actions, pi,term_state, action_map)\n",
        "    pi_mat = copy.deepcopy(pi_mat_temp)\n",
        "    print(pi_mat)\n",
        "\n",
        "    if stable:\n",
        "      print(\"\\nPolicy Converged\\n\")\n",
        "      fin_policy(pi_mat,dir,grid_rows,grid_cols,term_state)\n",
        "      break\n",
        "    i+=1"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNpSuKcqzEUj",
        "outputId": "d477a9bd-c9d1-4950-f3aa-0a06ac8d3c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_rows = 4\n",
        "grid_cols = 4\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "action_map = {0:(1,0),1:(0,1),2:(-1,0),3:(0,-1)}\n",
        "pi = 0.25\n",
        "term_state = [(0,0),(grid_rows-1,grid_cols-1)]\n",
        "dir = {0:\"D\", 1:\"R\", 2:\"U\", 3:\"L\"}\n",
        "theta = 0.00001\n",
        "grid_4x4_PI(grid_rows, grid_cols, actions, pi,term_state, theta, action_map,dir)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0\n",
            "Evaluating Policy...\n",
            "[[  0.         -13.99993529 -19.99990698 -21.99989761]\n",
            " [-13.99993529 -17.9999206  -19.99991379 -19.99991477]\n",
            " [-19.99990698 -19.99991379 -17.99992725 -13.99994569]\n",
            " [-21.99989761 -19.99991477 -13.99994569   0.        ]]\n",
            "Improving Policy...\n",
            "[[[0.25 0.25 0.25 0.25]\n",
            "  [0.   0.   0.   1.  ]\n",
            "  [0.   0.   0.   1.  ]\n",
            "  [0.   0.   0.   1.  ]]\n",
            "\n",
            " [[0.   0.   1.   0.  ]\n",
            "  [0.   0.   0.5  0.5 ]\n",
            "  [0.   0.   0.   1.  ]\n",
            "  [1.   0.   0.   0.  ]]\n",
            "\n",
            " [[0.   0.   1.   0.  ]\n",
            "  [0.   0.   1.   0.  ]\n",
            "  [0.   1.   0.   0.  ]\n",
            "  [1.   0.   0.   0.  ]]\n",
            "\n",
            " [[0.   0.   1.   0.  ]\n",
            "  [0.   1.   0.   0.  ]\n",
            "  [0.   1.   0.   0.  ]\n",
            "  [0.25 0.25 0.25 0.25]]]\n",
            "Iteration 1\n",
            "Evaluating Policy...\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "Improving Policy...\n",
            "[[[0.25 0.25 0.25 0.25]\n",
            "  [0.   0.   0.   1.  ]\n",
            "  [0.   0.   0.   1.  ]\n",
            "  [0.5  0.   0.   0.5 ]]\n",
            "\n",
            " [[0.   0.   1.   0.  ]\n",
            "  [0.   0.   0.5  0.5 ]\n",
            "  [0.25 0.25 0.25 0.25]\n",
            "  [1.   0.   0.   0.  ]]\n",
            "\n",
            " [[0.   0.   1.   0.  ]\n",
            "  [0.25 0.25 0.25 0.25]\n",
            "  [0.5  0.5  0.   0.  ]\n",
            "  [1.   0.   0.   0.  ]]\n",
            "\n",
            " [[0.   0.5  0.5  0.  ]\n",
            "  [0.   1.   0.   0.  ]\n",
            "  [0.   1.   0.   0.  ]\n",
            "  [0.25 0.25 0.25 0.25]]]\n",
            "Iteration 2\n",
            "Evaluating Policy...\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "Improving Policy...\n",
            "[[[0.25 0.25 0.25 0.25]\n",
            "  [0.   0.   0.   1.  ]\n",
            "  [0.   0.   0.   1.  ]\n",
            "  [0.5  0.   0.   0.5 ]]\n",
            "\n",
            " [[0.   0.   1.   0.  ]\n",
            "  [0.   0.   0.5  0.5 ]\n",
            "  [0.25 0.25 0.25 0.25]\n",
            "  [1.   0.   0.   0.  ]]\n",
            "\n",
            " [[0.   0.   1.   0.  ]\n",
            "  [0.25 0.25 0.25 0.25]\n",
            "  [0.5  0.5  0.   0.  ]\n",
            "  [1.   0.   0.   0.  ]]\n",
            "\n",
            " [[0.   0.5  0.5  0.  ]\n",
            "  [0.   1.   0.   0.  ]\n",
            "  [0.   1.   0.   0.  ]\n",
            "  [0.25 0.25 0.25 0.25]]]\n",
            "\n",
            "Policy Converged\n",
            "\n",
            "#; L; L; DL\n",
            "\n",
            "U; UL; DRUL; D\n",
            "\n",
            "U; DRUL; DR; D\n",
            "\n",
            "RU; R; R; #\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6_wMaNRGwDj"
      },
      "source": [
        "### Value Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqH7VYPNLKYI"
      },
      "source": [
        "A similar process to as followed in Question 4 is repeated with a few tweaks to fit the gridworld in Ex 4.1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO_fCwX0GvTK"
      },
      "source": [
        "def grid_4x4_value_VI(v_s, grid_rows, grid_cols, actions,term_state, theta):\n",
        "  cnt = 0\n",
        "  while (True): \n",
        "    print(\"Iteration \"+str(cnt))\n",
        "    delta = 0\n",
        "    for i in range(grid_rows):\n",
        "      for j in range(grid_cols):\n",
        "        if (i,j) not in term_state:\n",
        "          old_v = copy.deepcopy(v_s[i][j])\n",
        "          # val = -sys.max - 1\n",
        "          returns = []\n",
        "          for a in actions:\n",
        "            s_dash, r = next_step_ex41((i,j), a, grid_rows)\n",
        "            returns.append(r + v_s[s_dash[0]][s_dash[1]])\n",
        "          v_s[i][j] = max(returns)\n",
        "          delta = max(delta, abs(old_v - v_s[i][j]))\n",
        "    print(v_s)\n",
        "    cnt+=1\n",
        "    if delta<theta:\n",
        "      return v_s    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZrB5TdIKFuQ",
        "outputId": "4ecc7465-6141-4092-c210-f7f5a98c9d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "grid_rows = 4\n",
        "grid_cols = 4\n",
        "v_s = np.zeros((grid_rows, grid_cols))\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "theta = 0.00001\n",
        "term_state = [(0,0),(grid_rows-1,grid_cols-1)]\n",
        "v_star = grid_4x4_value_VI(v_s, grid_rows, grid_cols, actions,term_state, theta)\n",
        "# print(v_star)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0\n",
            "[[ 0. -1. -1. -1.]\n",
            " [-1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1.]\n",
            " [-1. -1. -1.  0.]]\n",
            "Iteration 1\n",
            "[[ 0. -1. -2. -2.]\n",
            " [-1. -2. -2. -2.]\n",
            " [-2. -2. -2. -1.]\n",
            " [-2. -2. -1.  0.]]\n",
            "Iteration 2\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "Iteration 3\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qh9VsfPOoaQ"
      },
      "source": [
        "def grid_4x4_policy_VI(v_star, pi_s, grid_rows, grid_cols, actions,term_state,dir):\n",
        "  for i in range(grid_rows):\n",
        "    for j in range(grid_cols):\n",
        "      if (i,j) not in term_state:\n",
        "        returns = []\n",
        "        for a in actions:\n",
        "          s_dash, r = next_step_ex41((i,j), a, grid_rows)\n",
        "          returns.append(r + v_star[s_dash[0]][s_dash[1]])\n",
        "        val = max(returns)\n",
        "        for k in range(len(returns)):\n",
        "          if val == returns[k]:\n",
        "              pi_s[i][j][k] = 1\n",
        "  print(pi_s)\n",
        "  fin_policy(pi_s,dir,grid_rows,grid_cols,term_state)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g8XuIAeUu8e",
        "outputId": "919edecd-f482-4630-9d06-1bf68695ca24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "grid_rows = 4\n",
        "grid_cols = 4\n",
        "actions = [(1,0),(0,1),(-1,0),(0,-1)]\n",
        "no_actions = len(actions)\n",
        "pi_s = np.zeros((grid_rows, grid_cols,no_actions))\n",
        "dir = {0:\"D\", 1:\"R\", 2:\"U\", 3:\"L\"}\n",
        "term_state = [(0,0),(grid_rows-1,grid_cols-1)]\n",
        "grid_4x4_policy_VI(v_star, pi_s, grid_rows, grid_cols, actions,term_state,dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [1. 0. 0. 1.]]\n",
            "\n",
            " [[0. 0. 1. 0.]\n",
            "  [0. 0. 1. 1.]\n",
            "  [1. 1. 1. 1.]\n",
            "  [1. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0.]\n",
            "  [1. 1. 1. 1.]\n",
            "  [1. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 1. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0.]]]\n",
            "#; L; L; DL\n",
            "\n",
            "U; UL; DRUL; D\n",
            "\n",
            "U; DRUL; DR; D\n",
            "\n",
            "RU; R; R; #\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezv_nfsblUE_"
      },
      "source": [
        "## Question 7: Policy Iteration, Book Exercise 4.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkuA1XchXVYY"
      },
      "source": [
        "## Appendices : Some Theory Questions implemented in Code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOuEk-L7XhNs"
      },
      "source": [
        "def ns(state,a,x):\n",
        "  if state == (0,0):\n",
        "    if a == 1:\n",
        "      return state, 4 \n",
        "    else:\n",
        "      temp = np.random.randint(10)\n",
        "      if temp <= 7 :\n",
        "        return (1,0), -8\n",
        "      else:\n",
        "        return (0,0), -8\n",
        "  else:\n",
        "    if a == 1:\n",
        "      temp = np.random.randint(10)\n",
        "      if temp <= 4 :\n",
        "        return (1,0), 4 \n",
        "      else:\n",
        "        return (0,0), 4 \n",
        "    else:\n",
        "      temp = np.random.randint(10)\n",
        "      if temp <= 8 :\n",
        "        return (1,0), -4\n",
        "      else:\n",
        "        return (0,0),  -4 "
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeHOgzy-XlJK"
      },
      "source": [
        "\n",
        "def grid_world_problem_optimal(gamma, grid_rows, grid_cols, actions, theta):\n",
        "  v_s_i = np.zeros((grid_rows,grid_cols))\n",
        "  v_s_i[0][0] = -2\n",
        "  v_s_i1 = np.zeros((grid_rows,grid_cols))\n",
        "  curr_state = -1\n",
        "  while(True):\n",
        "    curr_state += 1\n",
        "    print(curr_state)\n",
        "    for i in range(grid_rows):\n",
        "      for j in range(grid_cols):\n",
        "        max_v_s = []\n",
        "        for a in actions:\n",
        "          s_dash, r = ns((i,j),a,curr_state+1)\n",
        "          # print(r)\n",
        "          v_s = r + gamma*v_s_i[s_dash[0]][s_dash[1]]\n",
        "          max_v_s.append(v_s)\n",
        "        print(max_v_s)\n",
        "        v_s_i1[i][j] = max(max_v_s) \n",
        "    delta = abs(v_s_i1 - v_s_i).max()\n",
        "    # print(delta)\n",
        "    if delta<theta:\n",
        "      print(v_s_i1)\n",
        "      return v_s_i1\n",
        "    else:\n",
        "      v_s_i = copy.deepcopy(v_s_i1)\n",
        "      print(v_s_i1)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl6_CJGQXpz4",
        "outputId": "c514a5a0-31a1-4b5a-ceee-1ea4330044e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gamma = 0.5\n",
        "\n",
        "grid_rows = 2\n",
        "grid_cols = 1\n",
        "actions = [0,1]\n",
        "theta = 0.00001\n",
        "v_star = grid_world_problem_optimal(gamma, grid_rows, grid_cols, actions, theta)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[-9.0, 3.0]\n",
            "[-5.0, 4.0]\n",
            "[[3.]\n",
            " [4.]]\n",
            "1\n",
            "[-6.0, 5.5]\n",
            "[-2.0, 5.5]\n",
            "[[5.5]\n",
            " [5.5]]\n",
            "2\n",
            "[-5.25, 6.75]\n",
            "[-1.25, 6.75]\n",
            "[[6.75]\n",
            " [6.75]]\n",
            "3\n",
            "[-4.625, 7.375]\n",
            "[-0.625, 7.375]\n",
            "[[7.375]\n",
            " [7.375]]\n",
            "4\n",
            "[-4.3125, 7.6875]\n",
            "[-0.3125, 7.6875]\n",
            "[[7.6875]\n",
            " [7.6875]]\n",
            "5\n",
            "[-4.15625, 7.84375]\n",
            "[-0.15625, 7.84375]\n",
            "[[7.84375]\n",
            " [7.84375]]\n",
            "6\n",
            "[-4.078125, 7.921875]\n",
            "[-0.078125, 7.921875]\n",
            "[[7.921875]\n",
            " [7.921875]]\n",
            "7\n",
            "[-4.0390625, 7.9609375]\n",
            "[-0.0390625, 7.9609375]\n",
            "[[7.9609375]\n",
            " [7.9609375]]\n",
            "8\n",
            "[-4.01953125, 7.98046875]\n",
            "[-0.01953125, 7.98046875]\n",
            "[[7.98046875]\n",
            " [7.98046875]]\n",
            "9\n",
            "[-4.009765625, 7.990234375]\n",
            "[-0.009765625, 7.990234375]\n",
            "[[7.99023438]\n",
            " [7.99023438]]\n",
            "10\n",
            "[-4.0048828125, 7.9951171875]\n",
            "[-0.0048828125, 7.9951171875]\n",
            "[[7.99511719]\n",
            " [7.99511719]]\n",
            "11\n",
            "[-4.00244140625, 7.99755859375]\n",
            "[-0.00244140625, 7.99755859375]\n",
            "[[7.99755859]\n",
            " [7.99755859]]\n",
            "12\n",
            "[-4.001220703125, 7.998779296875]\n",
            "[-0.001220703125, 7.998779296875]\n",
            "[[7.9987793]\n",
            " [7.9987793]]\n",
            "13\n",
            "[-4.0006103515625, 7.9993896484375]\n",
            "[-0.0006103515625, 7.9993896484375]\n",
            "[[7.99938965]\n",
            " [7.99938965]]\n",
            "14\n",
            "[-4.00030517578125, 7.99969482421875]\n",
            "[-0.00030517578125, 7.99969482421875]\n",
            "[[7.99969482]\n",
            " [7.99969482]]\n",
            "15\n",
            "[-4.000152587890625, 7.999847412109375]\n",
            "[-0.000152587890625, 7.999847412109375]\n",
            "[[7.99984741]\n",
            " [7.99984741]]\n",
            "16\n",
            "[-4.0000762939453125, 7.9999237060546875]\n",
            "[-7.62939453125e-05, 7.9999237060546875]\n",
            "[[7.99992371]\n",
            " [7.99992371]]\n",
            "17\n",
            "[-4.000038146972656, 7.999961853027344]\n",
            "[-3.814697265625e-05, 7.999961853027344]\n",
            "[[7.99996185]\n",
            " [7.99996185]]\n",
            "18\n",
            "[-4.000019073486328, 7.999980926513672]\n",
            "[-1.9073486328125e-05, 7.999980926513672]\n",
            "[[7.99998093]\n",
            " [7.99998093]]\n",
            "19\n",
            "[-4.000009536743164, 7.999990463256836]\n",
            "[-9.5367431640625e-06, 7.999990463256836]\n",
            "[[7.99999046]\n",
            " [7.99999046]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rPr44bBq8os"
      },
      "source": [
        "def policy_eval(v_pi, grid_rows, grid_cols, actions, pi_mat,term_state, theta):\n",
        "  # v_pi = np.zeros((grid_rows,grid_cols))\n",
        "  while(True):\n",
        "    delta = 0\n",
        "    for i in range(grid_rows):\n",
        "      for j in range(grid_cols):\n",
        "        if (i,j) not in term_state:\n",
        "          v = copy.deepcopy(v_pi[i][j])\n",
        "          val = 0\n",
        "          c = 0\n",
        "          for a in actions:\n",
        "            s_dash, r = ns((i,j), a, grid_rows)\n",
        "            val += pi_mat[i][j][c] * (r + v_pi[s_dash[0]][s_dash[1]])\n",
        "            c += 1\n",
        "          v_pi[i][j] = val\n",
        "          delta = max(delta, abs(v_pi[i][j] - v))\n",
        "          # print(\"Delta \"+str(delta))\n",
        "    if delta < theta:\n",
        "      return v_pi\n",
        "    "
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e94THS0q8o8"
      },
      "source": [
        "def policy_improv(pi_mat,v_pi,grid_rows, grid_cols, actions, pi,term_state, action_map):\n",
        "  no_actions = len(actions)\n",
        "  # pi_mat = np.full((grid_rows,grid_cols,no_actions),pi)\n",
        "  policy_stable = True\n",
        "  for i in range(grid_rows):\n",
        "    for j in range(grid_cols):\n",
        "      if (i,j) not in term_state:\n",
        "        old_a = copy.deepcopy(pi_mat[i][j])\n",
        "        a_ind = 0\n",
        "        returns = []\n",
        "        for a in actions:\n",
        "          s_dash, r = ns((i,j), a, grid_rows)\n",
        "          returns.append(r + v_pi[s_dash[0]][s_dash[1]])\n",
        "        max_val = max(returns)\n",
        "        max_a = []\n",
        "        for  ret in range(len(returns)):\n",
        "          if returns[ret] == max_val:\n",
        "            max_a.append(ret)\n",
        "        pi_mat[i][j] = [0.] * no_actions\n",
        "        for a_ind in max_a:\n",
        "          pi_mat[i][j][a_ind] = (1/len(max_a))\n",
        "        for ind in range(len(old_a)):\n",
        "          if (old_a[ind] != pi_mat[i][j][ind]):\n",
        "            policy_stable = False\n",
        "            break\n",
        "  return pi_mat, policy_stable          "
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWZjLxSkq8pL"
      },
      "source": [
        "def PI(grid_rows, grid_cols, actions, pi,term_state, theta, action_map,dir):\n",
        "  i = 0\n",
        "  v_pi = np.zeros((grid_rows,grid_cols))\n",
        "  no_actions = len(actions)\n",
        "  pi_mat = np.full((grid_rows,grid_cols,no_actions),pi)\n",
        "  while True:\n",
        "    print(\"Iteration \"+str(i))\n",
        "    print(\"Evaluating Policy...\")\n",
        "\n",
        "    v = policy_eval(v_pi, grid_rows, grid_cols, actions, pi_mat,term_state, theta)\n",
        "    v_pi = copy.deepcopy(v)\n",
        "    print(v_pi)\n",
        "\n",
        "    print(\"Improving Policy...\")\n",
        "\n",
        "    pi_mat_temp, stable = policy_improv(pi_mat,v_pi,grid_rows, grid_cols, actions, pi,term_state, action_map)\n",
        "    pi_mat = copy.deepcopy(pi_mat_temp)\n",
        "    print(pi_mat)\n",
        "\n",
        "    if stable:\n",
        "      print(\"\\nPolicy Converged\\n\")\n",
        "      print(pi_mat)\n",
        "      break\n",
        "    i+=1"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh2AGEaUq8pT",
        "outputId": "eadcfc78-44ce-490a-ff0b-47b9b1c23f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "grid_rows = 2\n",
        "grid_cols = 1\n",
        "actions = [0,1]\n",
        "action_map = {0:0,1:1}\n",
        "pi = 0.5\n",
        "term_state = []\n",
        "dir = {}\n",
        "theta = 0.00001\n",
        "PI(grid_rows, grid_cols, actions, pi,term_state, theta, action_map,dir)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0\n",
            "Evaluating Policy...\n",
            "[[-1095.3626001]\n",
            " [-1091.3626001]]\n",
            "Improving Policy...\n",
            "[[[0. 1.]]\n",
            "\n",
            " [[0. 1.]]]\n",
            "Iteration 1\n",
            "Evaluating Policy...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-56c216db83c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-5781908374f8>\u001b[0m in \u001b[0;36mPI\u001b[0;34m(grid_rows, grid_cols, actions, pi, term_state, theta, action_map, dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating Policy...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mv_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-34bd95508deb>\u001b[0m in \u001b[0;36mpolicy_eval\u001b[0;34m(v_pi, grid_rows, grid_cols, actions, pi_mat, term_state, theta)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0ms_dash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpi_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv_pi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_dash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_dash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-b77486751567>\u001b[0m in \u001b[0;36mns\u001b[0;34m(state, a, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}